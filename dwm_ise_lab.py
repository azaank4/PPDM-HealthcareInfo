# -*- coding: utf-8 -*-
"""DWM_ISE_LAB.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JK5do6wWoNSLW4cQIo7VTZbJN4uEbbKm
"""


# Import all dependencies at the top
import pandas as pd
import numpy as np
from mlxtend.frequent_patterns import apriori, association_rules
from deap import base, creator, tools, algorithms
import random
import networkx as nx
import matplotlib.pyplot as plt
import seaborn as sns

# Clear any existing DEAP creators to avoid conflicts
if 'FitnessMin' in creator.__dict__:
    del creator.FitnessMin
if 'Individual' in creator.__dict__:
    del creator.Individual

# Upload the file manually
# Since we're working with a local CSV file, we don't need files.upload()
# The file 'heart-disease.csv' should be in the same directory as this script

# Load the dataset into a Pandas DataFrame
import pandas as pd
df = pd.read_csv('heart-disease.csv')

# Display the first few rows to ensure it's loaded correctly
print(df.head())

# Discretize 'age' and 'chol' into categories
df['age_group'] = pd.cut(df['age'], bins=[20, 40, 60, 80], labels=['young', 'middle', 'old'])
df['chol_level'] = pd.cut(df['chol'], bins=[0, 200, 400], labels=['low', 'high'])

# Select and one-hot encode categorical columns for Apriori
df_encoded = pd.get_dummies(df[['age_group', 'chol_level', 'target']])

# Show the transformed dataset
print(df_encoded.head())

# Modified fitness function with better error handling
def fitness(individual):
    try:
        return sum(individual),
    except Exception as e:
        print(f"Error in fitness calculation: {e}")
        return (float('inf'),)  # Return worst fitness in case of error

# Define a fitness function to minimize sensitive rules
def fitness(individual):
    # Example: Sum of changes made to the dataset to hide sensitive rules
    return sum(individual),  # Tuple required by DEAP

# Set up the genetic algorithm components
creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
creator.create("Individual", list, fitness=creator.FitnessMin)

toolbox = base.Toolbox()
toolbox.register("attr_bool", random.randint, 0, 1)
toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(df_encoded))
toolbox.register("population", tools.initRepeat, list, toolbox.individual)

toolbox.register("evaluate", fitness)
toolbox.register("mate", tools.cxTwoPoint)
toolbox.register("mutate", tools.mutFlipBit, indpb=0.05)
toolbox.register("select", tools.selTournament, tournsize=3)

# Run the genetic algorithm
population = toolbox.population(n=10)
algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=10, verbose=True)

# Get the best sanitization strategy
best_individual = tools.selBest(population, k=1)[0]
print("Best Sanitization Strategy:", best_individual)

# Apply the sanitization strategy (manually modify the dataset as needed)
df_sanitized = df_encoded.copy()

# Example: Modify specific rows/columns based on the best strategy
# (Customize this part based on the GA output)

# Re-run Apriori on the sanitized dataset
frequent_itemsets_after = apriori(df_sanitized, min_support=0.1, use_colnames=True)
rules_after = association_rules(frequent_itemsets_after, metric="confidence", min_threshold=0.5)

# Display sanitized rules to confirm sensitive rules are removed
print("Sanitized Association Rules:")
print(rules_after[['antecedents', 'consequents', 'support', 'confidence', 'lift']])

# Example: Filter for rules where 'target' appears in the consequent
rules_after_sensitive_check = rules_after[rules_after['consequents'].apply(lambda x: 'target' in str(x))]
print("Filtered Rules with 'target' in Consequents:")
print(rules_after_sensitive_check[['antecedents', 'consequents', 'support', 'confidence', 'lift']])

# Re-run Apriori with adjusted thresholds
frequent_itemsets_tweaked = apriori(df_encoded, min_support=0.15, use_colnames=True)
rules_tweaked = association_rules(frequent_itemsets_tweaked, metric="confidence", min_threshold=0.6)

print("Tweaked Rules:")
print(rules_tweaked[['antecedents', 'consequents', 'support', 'confidence', 'lift']])

# Create a network graph from the rules
G = nx.from_pandas_edgelist(rules_after, 'antecedents', 'consequents', ['confidence'])

# Plot the graph
plt.figure(figsize=(12, 8))
nx.draw(G, with_labels=True, node_size=3000, node_color='skyblue', font_size=10, font_color='black', edge_color='gray')
plt.title("Network Graph of Association Rules")
plt.show()

# Create a heatmap to show support values
pivot_table = rules_after.pivot(index='antecedents', columns='consequents', values='support').fillna(0)
plt.figure(figsize=(10, 6))
sns.heatmap(pivot_table, cmap='Blues', annot=True)
plt.title("Heatmap of Rule Support")
plt.show()